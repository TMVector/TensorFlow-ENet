{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 537 variables.\n",
      "Converted 537 variables to const ops.\n",
      "Writing tensorboard log\n",
      "Writing SavedModel\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Export directory already exists. Please specify a different export directory: ./logSM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e798b2b37455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Writing SavedModel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./logSM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_meta_graph_and_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERVING\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonny/anaconda3/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/saved_model/builder_impl.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, export_dir)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise AssertionError(\n\u001b[1;32m     87\u001b[0m           \u001b[0;34m\"Export directory already exists. Please specify a different export \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m           \"directory: %s\" % export_dir)\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Export directory already exists. Please specify a different export directory: ./logSM"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from enet import ENet, ENet_arg_scope\n",
    "import numpy as np\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "checkpoint_dir = \"./checkpoint\"\n",
    "checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "    image = tf.placeholder(dtype=tf.float32, shape=(1, 360, 480, 3), name=\"image_placeholder\")\n",
    "    \n",
    "    with slim.arg_scope(ENet_arg_scope()):\n",
    "        logits, probabilities = ENet(image,\n",
    "                                     num_classes=12,\n",
    "                                     batch_size=1,\n",
    "                                     is_training=False, # was True\n",
    "                                     reuse=None,\n",
    "                                     num_initial_blocks=1,\n",
    "                                     stage_two_repeat=2,\n",
    "                                     skip_connections=False)\n",
    "    \n",
    "    variables_to_restore = slim.get_variables_to_restore()\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    #sv = tf.train.Supervisor(logdir=None, init_fn=restore_fn)\n",
    "    \n",
    "    #with sv.managed_session() as sess:\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        #saver.restore(sess, checkpoint)\n",
    "        for var_name, _ in tf.contrib.framework.list_variables(checkpoint_dir):\n",
    "            var = tf.contrib.framework.load_variable(checkpoint_dir, var_name)\n",
    "            \n",
    "            #Rename loaded variables\n",
    "            new_name = var_name\n",
    "            if new_name.startswith('ENet/'):\n",
    "                new_name = new_name[5:]\n",
    "                var = tf.Variable(var, name=new_name)\n",
    "                #print(\"Renamed \" + var_name + \" to \" + new_name)\n",
    "            #else:\n",
    "            #    print(\"Variable \" + var_name + \" not renamed\")\n",
    "                \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        predictions = tf.argmax(probabilities, -1)\n",
    "        predictions = tf.cast(predictions, tf.float32)\n",
    "        \n",
    "        # See https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc\n",
    "        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "             sess\n",
    "            ,sess.graph_def\n",
    "            ,[predictions.name.split(\":\")[0]] #list of outputs\n",
    "        )\n",
    "        \n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        # Cheeky? >_>\n",
    "        tf.import_graph_def(\n",
    "             frozen_graph_def\n",
    "            ,return_elements=[predictions.name]\n",
    "            ,name=''\n",
    "        )\n",
    "        \n",
    "        #for op in sess.graph.get_operations():\n",
    "        #    print(op.name)\n",
    "        \n",
    "        image = sess.graph.get_tensor_by_name(\"image_placeholder:0\")\n",
    "        output = sess.graph.get_tensor_by_name(predictions.name)\n",
    "        segmentations = sess.run(output, feed_dict={image: np.random.rand(1, 360, 480, 3)})\n",
    "        \n",
    "        print(\"Writing tensorboard log\")\n",
    "        tf.summary.FileWriter('./log', graph=sess.graph).flush()\n",
    "\n",
    "        print(\"Writing SavedModel\")\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder('./logSM')\n",
    "        builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING])\n",
    "        builder.save()\n",
    "\n",
    "        \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
